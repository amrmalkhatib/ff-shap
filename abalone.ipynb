{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48baac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openml\n",
    "from openml.datasets import edit_dataset, fork_dataset, get_dataset\n",
    "\n",
    "data_name = 'abalone'\n",
    "\n",
    "data = openml.datasets.get_dataset(720)\n",
    "\n",
    "train_X, labels, categorical_indicator, attribute_names = data.get_data(\n",
    "    target=data.default_target_attribute, dataset_format=\"dataframe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29028fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapreg  # https://github.com/iancovert/shapley-regression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1539632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "...      ...       ...     ...           ...             ...             ...   \n",
       "4172   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
       "4173   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
       "4174   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
       "4175   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
       "4176   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
       "\n",
       "      Shell weight  Sex_M  Sex_F  Sex_I  \n",
       "0           0.1500      1      0      0  \n",
       "1           0.0700      1      0      0  \n",
       "2           0.2100      0      1      0  \n",
       "3           0.1550      1      0      0  \n",
       "4           0.0550      0      0      1  \n",
       "...            ...    ...    ...    ...  \n",
       "4172        0.2490      0      1      0  \n",
       "4173        0.2605      1      0      0  \n",
       "4174        0.3080      1      0      0  \n",
       "4175        0.2960      0      1      0  \n",
       "4176        0.4950      1      0      0  \n",
       "\n",
       "[4177 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nominal = [b for a, b in zip(categorical_indicator, attribute_names) if a]\n",
    "dummied_data = pd.get_dummies(train_X, columns=nominal)\n",
    "\n",
    "dummied_data.fillna(0, inplace=True)\n",
    "dummied_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6244fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train_, Y_test_ = train_test_split(dummied_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, Y_train_, Y_val_ = train_test_split(\n",
    "    X_train, Y_train_, test_size=0.2, random_state=0)\n",
    "\n",
    "# Data scaling\n",
    "num_features = X_train.shape[1]\n",
    "feature_names = X_train.columns.tolist()\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train_norm = ss.transform(X_train)\n",
    "X_val_norm = ss.transform(X_val)\n",
    "X_test_norm = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25692282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2672, 10) (669, 10) (836, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_norm.shape, X_val_norm.shape, X_test_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd005982",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = pd.get_dummies(Y_train_)\n",
    "Y_test = pd.get_dummies(Y_test_)\n",
    "Y_val = pd.get_dummies(Y_val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d1683dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2672, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c82a5b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2168    P\n",
       "536     N\n",
       "1180    N\n",
       "1244    P\n",
       "3363    N\n",
       "       ..\n",
       "542     N\n",
       "2695    P\n",
       "3612    N\n",
       "4061    N\n",
       "3966    P\n",
       "Name: binaryClass, Length: 2672, dtype: category\n",
       "Categories (2, object): ['P' < 'N']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60d7c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'P': 1, 'N': 0}\n",
    "\n",
    "\n",
    "Y_train_ = Y_train_.replace(mapping)\n",
    "Y_test_ = Y_test_.replace(mapping)\n",
    "Y_val_ = Y_val_.replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e19c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2168    1\n",
       "536     0\n",
       "1180    0\n",
       "1244    1\n",
       "3363    0\n",
       "       ..\n",
       "542     0\n",
       "2695    1\n",
       "3612    0\n",
       "4061    0\n",
       "3966    1\n",
       "Name: binaryClass, Length: 2672, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dc50df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:09:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB test_acc: 0.7757847533632287\n",
      "recall: 0.774387515882532\n",
      "precision: 0.7768398815542394\n",
      "f_score: 0.7747656755009696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "xg_boost = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, \n",
    "                             learning_rate=0.01, n_estimators= 100, reg_lambda=0.001)\n",
    "\n",
    "xgb_clf = xg_boost.fit(X_train_norm, Y_train_)\n",
    "val_acc = xgb_clf.score(X_val_norm, Y_val_)\n",
    "val_pred = xgb_clf.predict(X_val_norm)\n",
    "f_score = f1_score(Y_val_, val_pred, average='macro')\n",
    "prec = precision_score(Y_val_, val_pred, average='macro')\n",
    "recall = recall_score(Y_val_, val_pred, average='macro')\n",
    "\n",
    "print(f'XGB test_acc: {val_acc}\\nrecall: {recall}\\nprecision: {prec}\\nf_score: {f_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d219570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastshap.utils import MaskLayer1d\n",
    "from fastshap import Surrogate, KLDivLoss\n",
    "from ff_shap_training import BlackBoxWrapper, FF_SHAP_Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c36e927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bb = BlackBoxWrapper(xgb_clf, ss, num_features)\n",
    "\n",
    "def imputer(x, S):\n",
    "    x = torch.tensor(x, dtype=torch.float32, device=device)\n",
    "    S = torch.tensor(S, dtype=torch.float32, device=device)\n",
    "    pred = bb(x, S)\n",
    "    return pred.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a96ff518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved explanations\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os.path\n",
    "\n",
    "#Generate Explanations for test data\n",
    "\n",
    "if os.path.isfile(f'{data_name}/{data_name}_unbiased_exp.pickle'):\n",
    "    print('Loading saved explanations')\n",
    "    with open(f'{data_name}/{data_name}_unbiased_exp.pickle', 'rb') as file:\n",
    "        unbiased_exp = pickle.load(file)\n",
    "    with open(f'{data_name}/{data_name}_kernel_exp.pickle', 'rb') as file:\n",
    "        kernel_exp = pickle.load(file)\n",
    "        \n",
    "else:\n",
    "    unbiased_exp = []\n",
    "    kernel_exp = []\n",
    "    for i in tqdm(range(len(X_test_norm))):\n",
    "        game = shapreg.games.PredictionGame(imputer, X_test_norm[i])\n",
    "        tshap_values, all_results = shapreg.shapley.ShapleyRegression(\n",
    "            game, batch_size=64, paired_sampling=True, detect_convergence=True,\n",
    "            bar=True, return_all=True)\n",
    "        unbiased_exp.append(tshap_values)\n",
    "        kernel_exp.append(all_results)\n",
    "\n",
    "    with open(f'{data_name}/{data_name}_unbiased_exp.pickle', 'wb') as file:\n",
    "        pickle.dump(unbiased_exp, file)\n",
    "    \n",
    "    with open(f'{data_name}/{data_name}_kernel_exp.pickle', 'wb') as file:\n",
    "        pickle.dump(kernel_exp, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f09bd51",
   "metadata": {},
   "source": [
    "# FastSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16513da5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved explainer model\n"
     ]
    }
   ],
   "source": [
    "from fastshap import FastSHAP\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Check for model\n",
    "if os.path.isfile(f'{data_name}/{data_name}_explainer_fastSHAP_bb.pt'):\n",
    "    print('Loading saved explainer model')\n",
    "    explainer = torch.load(f'{data_name}/{data_name}_explainer_fastSHAP_bb.pt').to(device)\n",
    "    fastshap_bb = FastSHAP(explainer, bb, normalization='additive', link=None)\n",
    "\n",
    "else:\n",
    "    # Create explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        nn.Linear(num_features, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, Y_train.shape[1] * num_features)).to(device)\n",
    "\n",
    "    # Set up FastSHAP object\n",
    "    fastshap_bb = FastSHAP(explainer, bb, normalization='additive', link=None)\n",
    "\n",
    "    # Train\n",
    "    fastshap_bb.train(\n",
    "        X_train_norm,\n",
    "        X_val_norm[:100],\n",
    "        batch_size=64,\n",
    "        num_samples=64,\n",
    "        max_epochs=400,\n",
    "        validation_samples=128,\n",
    "        verbose=True,\n",
    "        lookback=5)\n",
    "    \n",
    "    # Save explainer\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, f'{data_name}/{data_name}_explainer_fastSHAP_bb.pt')\n",
    "    explainer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34fc0e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 distance: 0.08552393905503626\n",
      "cosine sim: 0.9480855880219956\n",
      "spearman corr: 0.8101521746951109\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "test_pred = xgb_clf.predict(X_test_norm)\n",
    "fastshap_values = fastshap_bb.shap_values(X_test_norm)\n",
    "\n",
    "pred_fastshap_values = np.array([fastshap_values[i] for i, l in enumerate(test_pred)])\n",
    "unbiased_values = np.array([unbiased_exp[i].values for i, l in enumerate(test_pred)])\n",
    "\n",
    "l2_dis = []\n",
    "cos_sim = []\n",
    "spearman_c = []\n",
    "\n",
    "for i in range(len(test_pred)):\n",
    "    fastshap_vs = pred_fastshap_values[i].reshape(-1)\n",
    "    unbiased_vs = unbiased_values[i].reshape(-1)\n",
    "\n",
    "    l2_dis.append(norm(unbiased_vs - fastshap_vs))\n",
    "    cos_sim.append(np.dot(unbiased_vs, fastshap_vs)/(norm(unbiased_vs)*norm(fastshap_vs)))\n",
    "    coef, p = spearmanr(unbiased_vs, fastshap_vs)\n",
    "    spearman_c.append(coef)\n",
    "    \n",
    "mean_l2_dis = np.mean(l2_dis, axis=0)\n",
    "mean_cos_sim = np.mean(cos_sim, axis=0)\n",
    "mean_spearman_c = np.mean(spearman_c, axis=0)\n",
    "\n",
    "print(f'l2 distance: {mean_l2_dis}\\ncosine sim: {mean_cos_sim}\\nspearman corr: {mean_spearman_c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd71f0b",
   "metadata": {},
   "source": [
    "# FF-SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f860621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved explanations\n"
     ]
    }
   ],
   "source": [
    "#Generate Explanations for training data\n",
    "\n",
    "if os.path.isfile(f'{data_name}/{data_name}_training_exp.pickle'):\n",
    "    print('Loading saved explanations')\n",
    "    with open(f'{data_name}/{data_name}_training_exp.pickle', 'rb') as file:\n",
    "        training_exp = pickle.load(file)\n",
    "        \n",
    "else:\n",
    "    training_exp = []\n",
    "    for i in tqdm(range(len(X_train_norm))):\n",
    "        game = shapreg.games.PredictionGame(imputer, X_train_norm[i])\n",
    "        tshap_values, all_results = shapreg.shapley.ShapleyRegression(\n",
    "            game, batch_size=256, paired_sampling=True, detect_convergence=True,\n",
    "            bar=False, return_all=True)\n",
    "        training_exp.append(tshap_values)\n",
    "        \n",
    "    with open(f'{data_name}/{data_name}_training_exp.pickle', 'wb') as file:\n",
    "        pickle.dump(training_exp, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e24f73f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved explanations\n"
     ]
    }
   ],
   "source": [
    "#Generate Explanations for development data\n",
    "\n",
    "if os.path.isfile(f'{data_name}/{data_name}_val_exp.pickle'):\n",
    "    print('Loading saved explanations')\n",
    "    with open(f'{data_name}/{data_name}_val_exp.pickle', 'rb') as file:\n",
    "        val_exp = pickle.load(file)\n",
    "\n",
    "else:\n",
    "    val_exp = []\n",
    "    for i in tqdm(range(len(X_val_norm))):\n",
    "        game = shapreg.games.PredictionGame(imputer, X_val_norm[i])\n",
    "        tshap_values, all_results = shapreg.shapley.ShapleyRegression(\n",
    "            game, batch_size=256, paired_sampling=True, detect_convergence=True,\n",
    "            bar=False, return_all=True)\n",
    "        val_exp.append(tshap_values)\n",
    "        \n",
    "    with open(f'{data_name}/{data_name}_val_exp.pickle', 'wb') as file:\n",
    "        pickle.dump(val_exp, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df7d5b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = np.array([training_exp[i].values.reshape(-1) for i, l in enumerate(X_train_norm)])\n",
    "val_targets = np.array([val_exp[i].values.reshape(-1) for i, l in enumerate(X_val_norm)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd07a3d3",
   "metadata": {},
   "source": [
    "# Training on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfb97799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved explainer model\n"
     ]
    }
   ],
   "source": [
    "from ff_shap_training import BlackBoxWrapper, FF_SHAP_Training\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Check for model\n",
    "if os.path.isfile(f'{data_name}/{data_name}_sampling_fastSHAP.pt'):\n",
    "    print('Loading saved explainer model')\n",
    "    explainer = torch.load(f'{data_name}/{data_name}_sampling_fastSHAP.pt').to(device)\n",
    "    ex_fastshap = FF_SHAP_Training(explainer, bb, num_features, Y_train.shape[1])\n",
    "\n",
    "else:\n",
    "    # Create explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        nn.Linear(num_features+Y_train.shape[1], 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, Y_train.shape[1] * num_features)).to(device)\n",
    "\n",
    "    # Set up FastSHAP object\n",
    "    ex_fastshap = FF_SHAP_Training(explainer, bb, num_features, Y_train.shape[1])\n",
    "\n",
    "    # Train\n",
    "    ex_fastshap.train(\n",
    "        X_train_norm,\n",
    "        train_targets,\n",
    "        X_val_norm[:512],\n",
    "        val_targets[:512],\n",
    "        batch_size=64,\n",
    "        num_samples=64,\n",
    "        max_epochs=400,\n",
    "        lr=2e-3,\n",
    "        verbose=True,\n",
    "        sampling=False,\n",
    "        lookback=5)\n",
    "    \n",
    "    # Save explainer\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, f'{data_name}/{data_name}_sampling_fastSHAP.pt')\n",
    "    explainer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ce05a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 distance: 0.08359368275257573\n",
      "cosine sim: 0.9782462787304702\n",
      "spearman corr: 0.8609885958916429\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "test_pred = xgb_clf.predict(X_test_norm)\n",
    "fastshap_values = ex_fastshap.predict(X_test_norm).cpu().data.numpy()\n",
    "\n",
    "pred_fastshap_values = np.array([fastshap_values[i] for i, l in enumerate(test_pred)])\n",
    "unbiased_values = np.array([unbiased_exp[i].values for i, l in enumerate(test_pred)])\n",
    "\n",
    "l2_dis = []\n",
    "cos_sim = []\n",
    "spearman_c = []\n",
    "\n",
    "for i in range(len(test_pred)):\n",
    "    fastshap_vs = pred_fastshap_values[i].reshape(-1)\n",
    "    unbiased_vs = unbiased_values[i].reshape(-1)\n",
    "\n",
    "    l2_dis.append(norm(unbiased_vs - fastshap_vs))\n",
    "    cos_sim.append(np.dot(unbiased_vs, fastshap_vs)/(norm(unbiased_vs)*norm(fastshap_vs)))\n",
    "    coef, p = spearmanr(unbiased_vs, fastshap_vs)\n",
    "    spearman_c.append(coef)\n",
    "    \n",
    "mean_l2_dis = np.mean(l2_dis, axis=0)\n",
    "mean_cos_sim = np.mean(cos_sim, axis=0)\n",
    "mean_spearman_c = np.mean(spearman_c, axis=0)\n",
    "\n",
    "print(f'l2 distance: {mean_l2_dis}\\ncosine sim: {mean_cos_sim}\\nspearman corr: {mean_spearman_c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984b9d1",
   "metadata": {},
   "source": [
    "# Training using 60% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38c31c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1604"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = int(np.ceil(len(X_train_norm)*0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03fb78a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved explainer model\n"
     ]
    }
   ],
   "source": [
    "from ff_shap_training import BlackBoxWrapper, FF_SHAP_Training\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Check for model\n",
    "if os.path.isfile(f'{data_name}/{data_name}_60_ffastSHAP.pt'):\n",
    "    print('Loading saved explainer model')\n",
    "    explainer = torch.load(f'{data_name}/{data_name}_60_ffastSHAP.pt').to(device)\n",
    "    ex_fastshap = FF_SHAP_Training(explainer, bb, num_features, Y_train.shape[1])\n",
    "\n",
    "else:\n",
    "    # Create explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        nn.Linear(num_features+Y_train.shape[1], 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, Y_train.shape[1] * num_features)).to(device)\n",
    "\n",
    "    # Set up FastSHAP object\n",
    "    ex_fastshap = FF_SHAP_Training(explainer, bb, num_features, Y_train.shape[1])\n",
    "\n",
    "    # Train\n",
    "    ex_fastshap.train(\n",
    "        X_train_norm[:ind],\n",
    "        train_targets[:ind],\n",
    "        X_val_norm[:512],\n",
    "        val_targets[:512],\n",
    "        batch_size=64,\n",
    "        num_samples=64,\n",
    "        max_epochs=400,\n",
    "        lr=2e-3,\n",
    "        verbose=True,\n",
    "        sampling=False,\n",
    "        lookback=5)\n",
    "    \n",
    "    # Save explainer\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, f'{data_name}/{data_name}_60_ffastSHAP.pt')\n",
    "    explainer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16aebb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 distance: 0.08870551835738033\n",
      "cosine sim: 0.9726661084617213\n",
      "spearman corr: 0.8509137676727704\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "test_pred = xgb_clf.predict(X_test_norm)\n",
    "fastshap_values = ex_fastshap.predict(X_test_norm).cpu().data.numpy()\n",
    "\n",
    "pred_fastshap_values = np.array([fastshap_values[i] for i, l in enumerate(test_pred)])\n",
    "unbiased_values = np.array([unbiased_exp[i].values for i, l in enumerate(test_pred)])\n",
    "\n",
    "l2_dis = []\n",
    "cos_sim = []\n",
    "spearman_c = []\n",
    "\n",
    "for i in range(len(test_pred)):\n",
    "    fastshap_vs = pred_fastshap_values[i].reshape(-1)\n",
    "    unbiased_vs = unbiased_values[i].reshape(-1)\n",
    "\n",
    "    l2_dis.append(norm(unbiased_vs - fastshap_vs))\n",
    "    cos_sim.append(np.dot(unbiased_vs, fastshap_vs)/(norm(unbiased_vs)*norm(fastshap_vs)))\n",
    "    coef, p = spearmanr(unbiased_vs, fastshap_vs)\n",
    "    spearman_c.append(coef)\n",
    "    \n",
    "mean_l2_dis = np.mean(l2_dis, axis=0)\n",
    "mean_cos_sim = np.mean(cos_sim, axis=0)\n",
    "mean_spearman_c = np.mean(spearman_c, axis=0)\n",
    "\n",
    "print(f'l2 distance: {mean_l2_dis}\\ncosine sim: {mean_cos_sim}\\nspearman corr: {mean_spearman_c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec86ed5",
   "metadata": {},
   "source": [
    "# Training using 30% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b641068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = int(np.ceil(len(X_train_norm)*0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3dc18dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved explainer model\n"
     ]
    }
   ],
   "source": [
    "from ff_shap_training import BlackBoxWrapper, FF_SHAP_Training\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Check for model\n",
    "if os.path.isfile(f'{data_name}/{data_name}_30_ffastSHAP.pt'):\n",
    "    print('Loading saved explainer model')\n",
    "    explainer = torch.load(f'{data_name}/{data_name}_30_ffastSHAP.pt').to(device)\n",
    "    ex_fastshap = FF_SHAP_Training(explainer, bb, num_features, Y_train.shape[1])\n",
    "\n",
    "else:\n",
    "    # Create explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        nn.Linear(num_features+Y_train.shape[1], 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, Y_train.shape[1] * num_features)).to(device)\n",
    "\n",
    "    # Set up FastSHAP object\n",
    "    ex_fastshap = FF_SHAP_Training(explainer, bb, num_features, Y_train.shape[1])\n",
    "\n",
    "    # Train\n",
    "    ex_fastshap.train(\n",
    "        X_train_norm[:ind],\n",
    "        train_targets[:ind],\n",
    "        X_val_norm[:512],\n",
    "        val_targets[:512],\n",
    "        batch_size=64,\n",
    "        num_samples=64,\n",
    "        max_epochs=400,\n",
    "        lr=2e-3,\n",
    "        verbose=True,\n",
    "        sampling=False,\n",
    "        lookback=5)\n",
    "    \n",
    "    # Save explainer\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, f'{data_name}/{data_name}_30_ffastSHAP.pt')\n",
    "    explainer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd0cbbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 distance: 0.10368585405717788\n",
      "cosine sim: 0.9649732049229227\n",
      "spearman corr: 0.827251142209591\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "test_pred = xgb_clf.predict(X_test_norm)\n",
    "fastshap_values = ex_fastshap.predict(X_test_norm).cpu().data.numpy()\n",
    "\n",
    "pred_fastshap_values = np.array([fastshap_values[i] for i, l in enumerate(test_pred)])\n",
    "unbiased_values = np.array([unbiased_exp[i].values for i, l in enumerate(test_pred)])\n",
    "\n",
    "l2_dis = []\n",
    "cos_sim = []\n",
    "spearman_c = []\n",
    "\n",
    "for i in range(len(test_pred)):\n",
    "    fastshap_vs = pred_fastshap_values[i].reshape(-1)\n",
    "    unbiased_vs = unbiased_values[i].reshape(-1)\n",
    "\n",
    "    l2_dis.append(norm(unbiased_vs - fastshap_vs))\n",
    "    cos_sim.append(np.dot(unbiased_vs, fastshap_vs)/(norm(unbiased_vs)*norm(fastshap_vs)))\n",
    "    coef, p = spearmanr(unbiased_vs, fastshap_vs)\n",
    "    spearman_c.append(coef)\n",
    "    \n",
    "mean_l2_dis = np.mean(l2_dis, axis=0)\n",
    "mean_cos_sim = np.mean(cos_sim, axis=0)\n",
    "mean_spearman_c = np.mean(spearman_c, axis=0)\n",
    "\n",
    "print(f'l2 distance: {mean_l2_dis}\\ncosine sim: {mean_cos_sim}\\nspearman corr: {mean_spearman_c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9331ce14",
   "metadata": {},
   "source": [
    "# Training using 15% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b654f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = int(np.ceil(len(X_train_norm)*0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61e6233c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved explainer model\n"
     ]
    }
   ],
   "source": [
    "from ff_shap_training import BlackBoxWrapper, FF_SHAP_Training\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Check for model\n",
    "if os.path.isfile(f'{data_name}/{data_name}_15_ffastSHAP.pt'):\n",
    "    print('Loading saved explainer model')\n",
    "    explainer = torch.load(f'{data_name}/{data_name}_15_ffastSHAP.pt').to(device)\n",
    "    ex_fastshap = FF_SHAP_Training(explainer, bb, num_features, Y_train.shape[1])\n",
    "\n",
    "else:\n",
    "    # Create explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        nn.Linear(num_features+Y_train.shape[1], 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, Y_train.shape[1] * num_features)).to(device)\n",
    "\n",
    "    # Set up FastSHAP object\n",
    "    ex_fastshap = FF_SHAP_Training(explainer, bb, num_features, Y_train.shape[1])\n",
    "\n",
    "    # Train\n",
    "    ex_fastshap.train(\n",
    "        X_train_norm[:ind],\n",
    "        train_targets[:ind],\n",
    "        X_val_norm[:512],\n",
    "        val_targets[:512],\n",
    "        batch_size=64,\n",
    "        num_samples=64,\n",
    "        max_epochs=400,\n",
    "        lr=2e-3,\n",
    "        verbose=True,\n",
    "        sampling=False,\n",
    "        lookback=5)\n",
    "    \n",
    "    # Save explainer\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, f'{data_name}/{data_name}_15_ffastSHAP.pt')\n",
    "    explainer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ebdbd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 distance: 0.14637177174409305\n",
      "cosine sim: 0.9529542708494543\n",
      "spearman corr: 0.8027754793682771\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "test_pred = xgb_clf.predict(X_test_norm)\n",
    "fastshap_values = ex_fastshap.predict(X_test_norm).cpu().data.numpy()\n",
    "\n",
    "pred_fastshap_values = np.array([fastshap_values[i] for i, l in enumerate(test_pred)])\n",
    "unbiased_values = np.array([unbiased_exp[i].values for i, l in enumerate(test_pred)])\n",
    "\n",
    "l2_dis = []\n",
    "cos_sim = []\n",
    "spearman_c = []\n",
    "\n",
    "for i in range(len(test_pred)):\n",
    "    fastshap_vs = pred_fastshap_values[i].reshape(-1)\n",
    "    unbiased_vs = unbiased_values[i].reshape(-1)\n",
    "\n",
    "    l2_dis.append(norm(unbiased_vs - fastshap_vs))\n",
    "    cos_sim.append(np.dot(unbiased_vs, fastshap_vs)/(norm(unbiased_vs)*norm(fastshap_vs)))\n",
    "    coef, p = spearmanr(unbiased_vs, fastshap_vs)\n",
    "    spearman_c.append(coef)\n",
    "    \n",
    "mean_l2_dis = np.mean(l2_dis, axis=0)\n",
    "mean_cos_sim = np.mean(cos_sim, axis=0)\n",
    "mean_spearman_c = np.mean(spearman_c, axis=0)\n",
    "\n",
    "print(f'l2 distance: {mean_l2_dis}\\ncosine sim: {mean_cos_sim}\\nspearman corr: {mean_spearman_c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb4d9a0",
   "metadata": {},
   "source": [
    "# Training with MSE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75780239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved explainer model\n"
     ]
    }
   ],
   "source": [
    "from ff_shap_training import BlackBoxWrapper, FF_SHAP_Training\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Check for model\n",
    "if os.path.isfile(f'{data_name}/{data_name}_MSE_fastSHAP.pt'):\n",
    "    print('Loading saved explainer model')\n",
    "    explainer = torch.load(f'{data_name}/{data_name}_MSE_fastSHAP.pt').to(device)\n",
    "    ex_fastshap = FF_SHAP_Training(explainer, bb, num_features, Y_train.shape[1])\n",
    "\n",
    "else:\n",
    "    # Create explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        nn.Linear(num_features+Y_train.shape[1], 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, Y_train.shape[1] * num_features)).to(device)\n",
    "\n",
    "    # Set up FastSHAP object\n",
    "    ex_fastshap = FF_SHAP_Training(explainer, bb, num_features, Y_train.shape[1])\n",
    "\n",
    "    # Train\n",
    "    ex_fastshap.train(\n",
    "        X_train_norm,\n",
    "        train_targets,\n",
    "        X_val_norm[:512],\n",
    "        val_targets[:512],\n",
    "        batch_size=64,\n",
    "        num_samples=64,\n",
    "        max_epochs=400,\n",
    "        loss_func='MSE',\n",
    "        lr=2e-3,\n",
    "        verbose=True,\n",
    "        sampling=False,\n",
    "        lookback=5)\n",
    "    \n",
    "    # Save explainer\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, f'{data_name}/{data_name}_MSE_fastSHAP.pt')\n",
    "    explainer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2339dd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 distance: 0.05556413335936369\n",
      "cosine sim: 0.9719006268131446\n",
      "spearman corr: 0.8565600604381767\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "test_pred = xgb_clf.predict(X_test_norm)\n",
    "fastshap_values = ex_fastshap.predict(X_test_norm).cpu().data.numpy()\n",
    "\n",
    "pred_fastshap_values = np.array([fastshap_values[i] for i, l in enumerate(test_pred)])\n",
    "unbiased_values = np.array([unbiased_exp[i].values for i, l in enumerate(test_pred)])\n",
    "\n",
    "l2_dis = []\n",
    "cos_sim = []\n",
    "spearman_c = []\n",
    "\n",
    "for i in range(len(test_pred)):\n",
    "    fastshap_vs = pred_fastshap_values[i].reshape(-1)\n",
    "    unbiased_vs = unbiased_values[i].reshape(-1)\n",
    "\n",
    "    l2_dis.append(norm(unbiased_vs - fastshap_vs))\n",
    "    cos_sim.append(np.dot(unbiased_vs, fastshap_vs)/(norm(unbiased_vs)*norm(fastshap_vs)))\n",
    "    coef, p = spearmanr(unbiased_vs, fastshap_vs)\n",
    "    spearman_c.append(coef)\n",
    "    \n",
    "mean_l2_dis = np.mean(l2_dis, axis=0)\n",
    "mean_cos_sim = np.mean(cos_sim, axis=0)\n",
    "mean_spearman_c = np.mean(spearman_c, axis=0)\n",
    "\n",
    "print(f'l2 distance: {mean_l2_dis}\\ncosine sim: {mean_cos_sim}\\nspearman corr: {mean_spearman_c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad03f03f",
   "metadata": {},
   "source": [
    "# Training without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36d2a757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved explainer model\n"
     ]
    }
   ],
   "source": [
    "from ff_shap_training import BlackBoxWrapper, FF_SHAP_Training\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Check for model\n",
    "if os.path.isfile(f'{data_name}/{data_name}_NAug_fastSHAP.pt'):\n",
    "    print('Loading saved explainer model')\n",
    "    explainer = torch.load(f'{data_name}/{data_name}_NAug_fastSHAP.pt').to(device)\n",
    "    ex_fastshap = FF_SHAP_Training(explainer, bb, num_features, Y_train.shape[1], augmentation=False)\n",
    "\n",
    "else:\n",
    "    # Create explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        nn.Linear(num_features, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, Y_train.shape[1] * num_features)).to(device)\n",
    "\n",
    "    # Set up FastSHAP object\n",
    "    ex_fastshap = FF_SHAP_Training(explainer, bb, num_features, Y_train.shape[1], False)\n",
    "\n",
    "    # Train\n",
    "    ex_fastshap.train(\n",
    "        X_train_norm,\n",
    "        train_targets,\n",
    "        X_val_norm[:512],\n",
    "        val_targets[:512],\n",
    "        batch_size=64,\n",
    "        num_samples=64,\n",
    "        max_epochs=400,\n",
    "        loss_func='cosine',\n",
    "        lr=2e-3,\n",
    "        verbose=True,\n",
    "        sampling=False,\n",
    "        lookback=5)\n",
    "    \n",
    "    # Save explainer\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, f'{data_name}/{data_name}_NAug_fastSHAP.pt')\n",
    "    explainer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9265a3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 distance: 0.11100849499733473\n",
      "cosine sim: 0.9672739921852314\n",
      "spearman corr: 0.8428013814440407\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "test_pred = xgb_clf.predict(X_test_norm)\n",
    "fastshap_values = ex_fastshap.predict(X_test_norm).cpu().data.numpy()\n",
    "\n",
    "pred_fastshap_values = np.array([fastshap_values[i] for i, l in enumerate(test_pred)])\n",
    "unbiased_values = np.array([unbiased_exp[i].values for i, l in enumerate(test_pred)])\n",
    "\n",
    "l2_dis = []\n",
    "cos_sim = []\n",
    "spearman_c = []\n",
    "\n",
    "for i in range(len(test_pred)):\n",
    "    fastshap_vs = pred_fastshap_values[i].reshape(-1)\n",
    "    unbiased_vs = unbiased_values[i].reshape(-1)\n",
    "\n",
    "    l2_dis.append(norm(unbiased_vs - fastshap_vs))\n",
    "    cos_sim.append(np.dot(unbiased_vs, fastshap_vs)/(norm(unbiased_vs)*norm(fastshap_vs)))\n",
    "    coef, p = spearmanr(unbiased_vs, fastshap_vs)\n",
    "    spearman_c.append(coef)\n",
    "    \n",
    "mean_l2_dis = np.mean(l2_dis, axis=0)\n",
    "mean_cos_sim = np.mean(cos_sim, axis=0)\n",
    "mean_spearman_c = np.mean(spearman_c, axis=0)\n",
    "\n",
    "print(f'l2 distance: {mean_l2_dis}\\ncosine sim: {mean_cos_sim}\\nspearman corr: {mean_spearman_c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a23c4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
